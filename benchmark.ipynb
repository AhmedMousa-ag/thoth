{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac7aacf8",
   "metadata": {},
   "source": [
    "# Common Variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bce772",
   "metadata": {},
   "source": [
    "## Average Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af9e6227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "small_list = [random.randint(1, 100) for _ in range(50)]\n",
    "medium_list = [random.randint(1, 100) for _ in range(5000)]\n",
    "large_list = [random.randint(1, 100) for _ in range(500000)]\n",
    "extra_large_list = [random.randint(1, 100) for _ in range(5000000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6ce488",
   "metadata": {},
   "source": [
    "# PySpark Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f554b444",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import avg\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3d4da9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/08/30 16:50:01 WARN Utils: Your hostname, akm, resolves to a loopback address: 127.0.1.1; using 192.168.1.8 instead (on interface wlp0s20f3)\n",
      "25/08/30 16:50:01 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/08/30 16:50:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "#192.168.122.217    spark-master\n",
    "\n",
    "MASTER_IP = \"spark-master\"\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"Thoth Benchmark\")\n",
    "    .master(f\"spark://{MASTER_IP}:7077\")\n",
    "    # .config(\"spark.executor.memory\", \"1g\")\n",
    "    # .config(\"spark.driver.memory\", \"1g\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8ca27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|avg(value)|\n",
      "+----------+\n",
      "|     57.36|\n",
      "+----------+\n",
      "\n",
      "\n",
      "Time taken to process small DataFrame: 2.987133741378784 seconds\n",
      "+----------+\n",
      "|avg(value)|\n",
      "+----------+\n",
      "|   50.7672|\n",
      "+----------+\n",
      "\n",
      "\n",
      "Time taken to process medium DataFrame: 0.20919013023376465 seconds\n",
      "+----------+\n",
      "|avg(value)|\n",
      "+----------+\n",
      "|   50.4502|\n",
      "+----------+\n",
      "\n",
      "\n",
      "Time taken to process large DataFrame: 0.40839648246765137 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/08/30 16:50:13 WARN TaskSetManager: Stage 9 contains a task of very large size (6561 KiB). The maximum recommended task size is 1000 KiB.\n",
      "[Stage 9:>                                                          (0 + 3) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|avg(value)|\n",
      "+----------+\n",
      "|50.5175776|\n",
      "+----------+\n",
      "\n",
      "\n",
      "Time taken to process extra large DataFrame: 1.2565114498138428 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/08/30 16:50:24 WARN StandaloneAppClient$ClientEndpoint: Connection to 192.168.122.217:7077 failed; waiting for master to reconnect...\n",
      "25/08/30 16:50:24 WARN StandaloneSchedulerBackend: Disconnected from Spark cluster! Waiting for reconnection...\n",
      "25/08/30 16:50:29 ERROR TaskSchedulerImpl: Lost executor 0 on 0.0.0.0: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n"
     ]
    }
   ],
   "source": [
    "small_df = spark.createDataFrame(small_list, \"int\").toDF(\"value\")\n",
    "medium_df = spark.createDataFrame(medium_list, \"int\").toDF(\"value\")\n",
    "large_df = spark.createDataFrame(large_list, \"int\").toDF(\"value\")\n",
    "extra_large_list_df = spark.createDataFrame(extra_large_list, \"int\").toDF(\"value\")\n",
    "\n",
    "start_time = time.time()\n",
    "small_df.agg(avg(\"value\")).show()\n",
    "end_time = time.time()\n",
    "py_spark_small_list_time = end_time - start_time\n",
    "print(f\"\\nSpark Time taken to process small DataFrame: {py_spark_small_list_time} seconds\")\n",
    "\n",
    "start_time = time.time()\n",
    "medium_df.agg(avg(\"value\")).show()\n",
    "end_time = time.time()\n",
    "py_spark_medium_list_time = end_time - start_time\n",
    "print(f\"\\nSpark Time taken to process medium DataFrame: {py_spark_medium_list_time} seconds\")\n",
    "\n",
    "start_time = time.time()\n",
    "large_df.agg(avg(\"value\")).show()\n",
    "end_time = time.time()\n",
    "py_spark_large_list_time = end_time - start_time\n",
    "print(f\"\\nSpark Time taken to process large DataFrame: {py_spark_large_list_time} seconds\")\n",
    "\n",
    "start_time = time.time()\n",
    "extra_large_list_df.agg(avg(\"value\")).show()\n",
    "end_time = time.time()\n",
    "py_spark_extra_large_list_time = end_time - start_time\n",
    "print(f\"\\nSpark Time taken to process extra large DataFrame: {py_spark_extra_large_list_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d0c015",
   "metadata": {},
   "source": [
    "# Thoth BenchMark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae68b556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remote address changed to: ['192.168.122.217:50051', '192.168.122.215:50051']\n"
     ]
    }
   ],
   "source": [
    "from py_thoth.operations.vector import list_average\n",
    "from py_thoth.settings.connections import change_remote_address\n",
    "remote_addresses = [\"192.168.122.217:50051\", \"192.168.122.215:50051\"]\n",
    "# remote_addresses = [\"localhost:50051\", \"localhost:50052\"]\n",
    "# remote_addresses = [\"localhost:50051\"]\n",
    "change_remote_address(remote_addresses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08475d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configurations remote address: ['192.168.122.217:50051', '192.168.122.215:50051']\n",
      "Average Small List:  57.36\n",
      "\n",
      "Thoth Small List Time taken: 0.040738821029663086 seconds\n",
      "Configurations remote address: ['192.168.122.217:50051', '192.168.122.215:50051']\n",
      "Average Medium List:  50.7672\n",
      "\n",
      "Thoth Medium List Time taken: 0.04539155960083008 seconds\n",
      "Configurations remote address: ['192.168.122.217:50051', '192.168.122.215:50051']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mThoth Medium List Time taken: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mthoth_medium_list_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m seconds\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m start_time = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mAverage Large List: \u001b[39m\u001b[33m\"\u001b[39m, \u001b[43mlist_average\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlarge_list\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     15\u001b[39m end_time = time.time()\n\u001b[32m     16\u001b[39m thoth_large_list_time = end_time - start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Work/personal/thoth/py_thoth/utils/util.py:19\u001b[39m, in \u001b[36mrun_client.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Inject the stub into kwargs\u001b[39;00m\n\u001b[32m     18\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mstub\u001b[39m\u001b[33m\"\u001b[39m] = stub\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Work/personal/thoth/py_thoth/operations/vector.py:16\u001b[39m, in \u001b[36mlist_average\u001b[39m\u001b[34m(a, **kwargs)\u001b[39m\n\u001b[32m     10\u001b[39m operation_id = kwargs.get(\u001b[33m\"\u001b[39m\u001b[33moperation_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(uuid.uuid4()))\n\u001b[32m     11\u001b[39m req = mathop_pb2.ListAverageOperationRequest(\n\u001b[32m     12\u001b[39m     x=a,\n\u001b[32m     13\u001b[39m     operation_id=operation_id,\n\u001b[32m     14\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m res = \u001b[43mstub\u001b[49m\u001b[43m.\u001b[49m\u001b[43mListAverage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m res.result_average\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Work/virt-env/general/lib/python3.12/site-packages/grpc/_channel.py:1175\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable.__call__\u001b[39m\u001b[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[39m\n\u001b[32m   1166\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\n\u001b[32m   1167\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1168\u001b[39m     request: Any,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1173\u001b[39m     compression: Optional[grpc.Compression] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1174\u001b[39m ) -> Any:\n\u001b[32m-> \u001b[39m\u001b[32m1175\u001b[39m     state, call = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_blocking\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\n\u001b[32m   1177\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1178\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Work/virt-env/general/lib/python3.12/site-packages/grpc/_channel.py:1162\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable._blocking\u001b[39m\u001b[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[39m\n\u001b[32m   1145\u001b[39m state.target = _common.decode(\u001b[38;5;28mself\u001b[39m._target)\n\u001b[32m   1146\u001b[39m call = \u001b[38;5;28mself\u001b[39m._channel.segregated_call(\n\u001b[32m   1147\u001b[39m     cygrpc.PropagationConstants.GRPC_PROPAGATE_DEFAULTS,\n\u001b[32m   1148\u001b[39m     \u001b[38;5;28mself\u001b[39m._method,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1160\u001b[39m     \u001b[38;5;28mself\u001b[39m._registered_call_handle,\n\u001b[32m   1161\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1162\u001b[39m event = \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnext_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1163\u001b[39m _handle_event(event, state, \u001b[38;5;28mself\u001b[39m._response_deserializer)\n\u001b[32m   1164\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m state, call\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:388\u001b[39m, in \u001b[36mgrpc._cython.cygrpc.SegregatedCall.next_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:211\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._next_call_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:205\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._next_call_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:97\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._latent_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:80\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._internal_latent_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:61\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._next\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Average Small List: \", list_average(small_list))\n",
    "end_time = time.time()\n",
    "thoth_small_list_time = end_time - start_time\n",
    "print(f\"\\nThoth Small List Time taken: {thoth_small_list_time} seconds\")\n",
    "\n",
    "start_time = time.time()\n",
    "print(\"Average Medium List: \", list_average(medium_list))\n",
    "end_time = time.time()\n",
    "thoth_medium_list_time = end_time - start_time\n",
    "print(f\"\\nThoth Medium List Time taken: {thoth_medium_list_time} seconds\")\n",
    "\n",
    "start_time = time.time()\n",
    "print(\"Average Large List: \", list_average(large_list))\n",
    "end_time = time.time()\n",
    "thoth_large_list_time = end_time - start_time\n",
    "print(f\"\\nThoth Large List Time taken: {thoth_large_list_time} seconds\")\n",
    "\n",
    "start_time = time.time()\n",
    "print(\"Average Extra Large List: \", list_average(extra_large_list))\n",
    "end_time = time.time()\n",
    "thoth_extra_large_list_time = end_time - start_time\n",
    "print(f\"\\nThoth Extra Large Time taken: {thoth_extra_large_list_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a184cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7594840e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
